<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="CY">





<title>pytorch | Hexo</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    
    <link rel="stylesheet" href="/../fonts/iconfont2/iconfont.css">
    
    <link rel="stylesheet" href="/../fonts/iconfont3/iconfont.css">
    
    <link rel="stylesheet" href="/../fonts/iconfont4/iconfont.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    
    <script src="/js/jquery-3.6.0.min.js"></script>
    



    
    
        
    


<!-- 搜索的部分 -->



    <script>
    // function searchToggle() {
    //     const width = $(document.body).width()
    //     if(width > 479) {
    //         return;
    //     }
    //     const search = $('.search');
    //     const searchForm = $('.form-search')

    //     if(!search.hasClass("mobile-search")) {
    //         search.addClass("mobile-search");
    //     } else {
    //         search.removeClass("mobile-search");
    //     } 
    // }

    function searchToggle() {
        const width = $(document.body).width()
        if(width > 479) {
            return;
        }
        const search = $('.search');
        const searchForm = $('.form-search');
        const menuToggle = $('.menu-toggle');
        const title = $('.navbar-header-title ');

        if(!search.hasClass("mobile-search")) {
            search.addClass("mobile-search");
            menuToggle.addClass("open-search")
            title.addClass("mobile-title-hidden")
        } else {
            search.removeClass("mobile-search");
            menuToggle.removeClass("open-search")
            // title.css({visibility: 'visible'})
            title.removeClass("mobile-title-hidden")
        } 
    }



    function search(searchInputEl, formEl, flag) {
        const path = "/" + "search.json"; // 可以在public 下查看这个search.json
        $(formEl).submit(function(e){
            e.preventDefault();
            let target = null
            if(searchInputEl == null) {
                const screenWidth = $(document.body).width();
                target = screenWidth > 479 ? $('#pc-search-input') : $('#mobile-search-input');
                console.log(target);
            } else {
                target = $(searchInputEl)
            }

            if(!flag && target.val() === '') {
                return ;
            }

            $("#u-search").fadeIn(500, function() {
                $("body > .wrapper").addClass("modal-active");

                $.ajax({
                    url: path,
                    dataType: "json",
                    beforeSend: function (xhr) {
                        $input = target.val();
                        $(".form-input").val($input);
                        const loadingBar = $('.search-loading-bar') 
                        loadingBar.css({
                            width:'100%',
                            display: 'block'
                        });
                    },
                    success: function( datas ) {
                        console.log(datas);
                        const $resultPanel = $(".modal-body")[0];
                        let str = `<ul class="modal-results">`;
                        var keywords = $(".form-input").val().trim().toLowerCase().split(/[\s\-]+/);
                        $resultPanel.innerHTML = "";
                        let hasResult = false
                        let text = `<div class="no-result">找不到与关键词相关的内容....</div>`;

                        if ($(".form-input").val().trim().length <= 0) {
                            // 没有结果
                            $resultPanel.innerHTML = text;
                            return;
                        }
                        datas.forEach(function (data, index) {
                            var isMatch = true;
                            if (!data.title || data.title.trim() === '') {
                                data.title = "Untitled";
                            }
                            var data_title = data.title.trim().toLowerCase();
                            var data_content = data.content && data.content.trim().replace(/<[^>]+>/g, "").toLowerCase() || '';
                            var data_url = data.url;
                            var index_title = -1;
                            var index_content = -1;
                            var first_occur = -1;
                            // only match artiles with not empty contents
                            if (data_content !== '') {
                                keywords.forEach(function (keyword, i) {
                                    index_title = data_title.indexOf(keyword);
                                    index_content = data_content.indexOf(keyword);

                                    if (index_title < 0 && index_content < 0) {
                                        isMatch = false;
                                    } else {
                                        hasResult = true
                                        if (index_content < 0) {
                                            index_content = 0;
                                        }
                                        if (i == 0) {
                                            first_occur = index_content;
                                        }
                                    }
                                });
                            } else {
                                isMatch = false;
                            }
                            // show search results
                            if (isMatch) {
                                str += `<li class='result-item'><a href='${data_url}' class='result-item-detail'> <span class="title">${data_title}</span>`;
                                var content = data.content.trim().replace(/<[^>]+>/g, "");
                                if (first_occur >= 0) {
                                    // cut out 200 characters
                                    var start = first_occur - 40;
                                    var end = first_occur + 160;

                                    if (start < 0) {
                                        start = 0;
                                    }

                                    if (start == 0) {
                                        end = 200;
                                    }

                                    if (end > content.length) {
                                        end = content.length;
                                    }

                                    var match_content = content.substring(start, end);

                                    // highlight all keywords
                                    keywords.forEach(function (keyword) {
                                        var regS = new RegExp(keyword, "gi");
                                        match_content = match_content.replace(regS, `<em class="search-keyword">${keyword}</em>`);
                                    });

                                    str += `<span class="content"> ${match_content} ...</span></a>`;
                                }
                                str += "</li>";
                            }
                        });
                        str += "</ul>";
                        if(hasResult) {
                            $resultPanel.innerHTML = str;
                        } else {
                            $resultPanel.innerHTML = text;
                        }

                    },
                    complete: function() {
                        setTimeout(() => {
                                const loadingBar = $('.search-loading-bar') 
                                loadingBar.css({
                                    width:'0%',
                                    display: 'none'
                                });
                        }, 300)
                    }
                });
            })

        });
    }

    $(document).ready(function() {
        $('.modal-close').click(function () { 
            $("#u-search").fadeOut();
            $("body > .wrapper").removeClass("modal-active")
        })

        $('.modal-overlay').click(function() {
            $("#u-search").fadeOut();
            $("body > .wrapper").removeClass("modal-active")
        })
        search(null, ".form-search", false)
        search("#u-search-modal-form .form-input", ".u-search-modal-form", true)
    })
</script>

<meta name="generator" content="Hexo 6.1.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">CY&#39;s Blog</a></div>
            <div class="menu navbar-right">
				<!-- 这里表示的是pc端搜索框 -->
				
				
    <div class="search ">
        <div class="search-btn" onClick="searchToggle()">
            <img src="/image/search.png" class="search-btn-img" />
        </div>
        <form class="form-search">
            <input class="input" placeholder="点此搜索" autocomplete="off" id="pc-search-input"/>
        </form>
    </div>


                
                    <a class="menu-item" href="/archives">📚Posts</a>
                
                    <a class="menu-item" href="/category">📁Categories</a>
                
                    <a class="menu-item" href="/tag">🏷️Tags</a>
                
                    <a class="menu-item" href="/about">📑About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">CY&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
				<div class="navbar-mobile-right">
					
					
    <div class="search ">
        <div class="search-btn" onClick="searchToggle()">
            <img src="/image/search.png" class="search-btn-img" />
        </div>
        <form class="form-search">
            <input class="input" placeholder="点此搜索" autocomplete="off" id="mobile-search-input"/>
        </form>
    </div>


					<div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
				</div>
				
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">📚Posts</a>
                
                    <a class="menu-item" href="/category">📁Categories</a>
                
                    <a class="menu-item" href="/tag">🏷️Tags</a>
                
                    <a class="menu-item" href="/about">📑About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    document.ready(
        function () {
            tocbot.init({
                tocSelector: '.tocbot-list',
                contentSelector: '.post-content',
                headingSelector: 'h1, h2, h3, h4, h5',
                collapseDepth: 1,
                orderedList: false,
                scrollSmooth: true,
            })
        }
    )

    function expand_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 6,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "collapse_toc()");
        b.innerHTML = "Collapse all"
    }

    function collapse_toc() {
        var b = document.querySelector(".tocbot-toc-expand");
        tocbot.init({
            tocSelector: '.tocbot-list',
            contentSelector: '.post-content',
            headingSelector: 'h1, h2, h3, h4, h5',
            collapseDepth: 1,
            orderedList: false,
            scrollSmooth: true,
        });
        b.setAttribute("onclick", "expand_toc()");
        b.innerHTML = "Expand all"
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">pytorch</h1>
            
                <div class="post-meta">
                    
                        👨‍🎓Author: <a itemprop="author" rel="author" href="/">CY</a>
                    

                    
                        <span class="post-time">
                        📅Date: <a href="#">April 25, 2022&nbsp;&nbsp;18:54:33</a>
                        </span>
                    
                    
                        <span class="post-category">
							📚Category:
                            
                                <a href="/categories/source-code/">source code</a>
                            
                        </span>
                    
					
					
						<span class="post-count">
					📑Words:
						<a href="">2.5k</a>
						</span>
					
					
						<span class="post-count">
					⏱️Time:
						<a href="">10min</a>  
						</span>
					
                </div>
            
        </header>

        <div class="post-content">
            <h1 id="Module类"><a href="#Module类" class="headerlink" title="Module类"></a>Module类</h1><ul>
<li>module中的__getattr中有三个魔法函数，其有三个成员变量分别是<code>_parameters</code>、<code>_buffers</code>(统计量)和<code>_modules</code></li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 实例化模型后，参数已初始化</span></span><br><span class="line">test_module = Net()</span><br><span class="line"><span class="comment"># 返回模型中各个子模块层,返回的是有序字典，与named_children()区别，其返回的是元组</span></span><br><span class="line">test_module._modules</span><br><span class="line"><span class="comment"># 打印模块自身的Parameters、buff对象，不包括其中各个子模块</span></span><br><span class="line">test_module._parameters</span><br><span class="line">test_module._buffers</span><br><span class="line"></span><br><span class="line"><span class="comment"># named_modules()不仅返回自身模块还返回各个子模块 </span></span><br><span class="line"><span class="keyword">for</span> p <span class="keyword">in</span> test_module.named_modules():</span><br><span class="line">    <span class="built_in">print</span>(p)</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li>module中的<code>state_dict</code>方法<ol>
<li>首先，通过<code>_save_to_state_dict</code>方法先将当前模块的<code>parameters</code>和<code>buffers</code>变量存入<code>destination</code>字典</li>
<li>然后，遍历<code>self.modules.items()</code>子模块，将每个子模块的<code>parameters</code>和<code>buffers</code>变量存入<code>destination</code>字典</li>
<li>最后返回<code>destination</code>字典中包含所有模型状态参数，OrderedDict[key, value]</li>
</ol>
</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>module.state_dict().keys()</span><br><span class="line">[<span class="string">'bias'</span>, <span class="string">'weight'</span>]</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将网络参数保存到path文件中，不包含网络图结构和优化器参数等部分</span></span><br><span class="line">torch.save(test_module.state_dict(), path)</span><br><span class="line"></span><br><span class="line"><span class="comment">#———————————————————————————模型保存相关—————————————————————</span></span><br><span class="line"><span class="comment"># 保存网络参数和图结构，占用磁盘空间大</span></span><br><span class="line">torch.save(test_module, path)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 保存所有所有相关信息</span></span><br><span class="line">EPOCH = <span class="number">5</span></span><br><span class="line">PATH = <span class="string">"model.pt"</span></span><br><span class="line">LOSS = <span class="number">0.4</span></span><br><span class="line"></span><br><span class="line">torch.save({</span><br><span class="line">            <span class="string">'epoch'</span>: EPOCH,</span><br><span class="line">            <span class="string">'model_state_dict'</span>: net.state_dict(),</span><br><span class="line">            <span class="string">'optimizer_state_dict'</span>: optimizer.state_dict(),</span><br><span class="line">            <span class="string">'loss'</span>: LOSS,</span><br><span class="line">            }, PATH)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 再次实例化，是因为上面torch.save中没有保存网络图结构，要先构建图结构再去加载参数</span></span><br><span class="line">model = Net()</span><br><span class="line">optimizer = optim.SGD(net.parameters(), lr=<span class="number">0.001</span>, momentum=<span class="number">0.9</span>)</span><br><span class="line"></span><br><span class="line">checkpoint = torch.load(PATH)</span><br><span class="line"><span class="comment"># 传入字典对象</span></span><br><span class="line">model.load_state_dict(checkpoint[<span class="string">'model_state_dict'</span>])</span><br><span class="line">optimizer.load_state_dict(checkpoint[<span class="string">'optimizer_state_dict'</span>])</span><br><span class="line">epoch = checkpoint[<span class="string">'epoch'</span>]</span><br><span class="line">loss = checkpoint[<span class="string">'loss'</span>]</span><br></pre></td></tr></tbody></table></figure>

<ul>
<li><p>module中的<code>parameter</code>方法</p>
<ol>
<li>注意<code>parameter</code> 与<code>_parameters </code>区分，前者返回的是迭代器，包括当前模块和各个子模块的参数。后者返回的是当前模块中的参数。</li>
<li>其中会执行<code>named_papameters</code> 最终返回的是个迭代器对象[key, value]</li>
</ol>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span><span class="keyword">for</span> p <span class="keyword">in</span> test_module.named_parameters():</span><br><span class="line">    	<span class="built_in">print</span>(p)</span><br></pre></td></tr></tbody></table></figure>
</li>
<li><p>module中的<code>train</code> 方法</p>
<p><code>dropout</code> 和 <code>batchnorm</code> 都继承了Module类，都属于模型的子模块，当把模型设置为训练模式和验证模式时，相应的子模块也会设为对应的训练或验证模式</p>
</li>
</ul>
<h1 id="自动微分Forward与Reverse模式"><a href="#自动微分Forward与Reverse模式" class="headerlink" title="自动微分Forward与Reverse模式"></a>自动微分Forward与Reverse模式</h1><ul>
<li><h2 id="Forward计算流程"><a href="#Forward计算流程" class="headerlink" title="Forward计算流程"></a>Forward计算流程</h2></li>
</ul>
<p><img src="/2022/04/25/pytorch/image-20220426135242639.png" alt="forward"></p>
<p><strong>==特点==：</strong>前向计算过程中当前节点相对某个输入结点的梯度可计算得到；每次只能得到一个输入节点的导数如图中的x1</p>
<ul>
<li><h2 id="Reverse计算流程"><a href="#Reverse计算流程" class="headerlink" title="Reverse计算流程"></a>Reverse计算流程</h2></li>
</ul>
<p><img src="/2022/04/25/pytorch/image-20220426135907575.png" alt="reverse"></p>
<p><strong>==特点：==</strong> 反向计算过程中需要等待前向计算结束；一次性可以算出所有节点导数 </p>
<blockquote>
<p>图片出处：Automatic Differentiation in Machine Learning: a Survey</p>
</blockquote>
<h1 id="算子融合"><a href="#算子融合" class="headerlink" title="算子融合"></a>算子融合</h1><figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"></span><br><span class="line">in_channels = <span class="number">2</span></span><br><span class="line">out_channels =<span class="number">2</span></span><br><span class="line">kernel_size = <span class="number">3</span></span><br><span class="line">w = <span class="number">9</span></span><br><span class="line">h = <span class="number">9</span></span><br><span class="line"></span><br><span class="line">x = torch.ones(<span class="number">1</span>, in_channels, h, w)</span><br><span class="line">conv3 = nn.Conv2d(in_channels, out_channels, kernel_size, padding=<span class="string">"same"</span>)</span><br><span class="line">conv1 = nn.Conv2d(in_channels, out_channels, <span class="number">1</span>)    <span class="comment"># [2,2,1,1]</span></span><br><span class="line">result1 = x + conv3(x) + conv1(x)</span><br><span class="line"><span class="built_in">print</span>(result1)</span><br><span class="line"></span><br><span class="line"><span class="comment"># ——————————————————————--————将1*1卷积转为3*3——————————————————————————————————————</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># pad填充方式从里到外，每个维度都有上下和左右两个方向，四个1分别对应左右S上下填充0的个数</span></span><br><span class="line"><span class="comment"># [2,2,1,1] -&gt; [2,2,3,3]</span></span><br><span class="line">conv1_to_conv3 = F.pad(conv1.weight, [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>,<span class="number">0</span>]) </span><br><span class="line"></span><br><span class="line"><span class="comment"># 实例化卷积</span></span><br><span class="line">conv1_3 = nn.Conv2d(in_channels, out_channels, kernel_size, padding=<span class="string">"same"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 将卷积参数用1*1填充后的参数替代，weight是parameter类，要用nn.Parameter()包装</span></span><br><span class="line">conv1_3.weight = nn.Parameter(conv1_to_conv3)</span><br><span class="line">conv1_3.bias = conv1.bias</span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------------如何将输入x本身化为3*3卷积表示—————————————————————————————————</span></span><br><span class="line"><span class="comment">#------------------------1. 必须是1*1的卷积不考虑相邻点融合--------------—————————————————————</span></span><br><span class="line"><span class="comment">#-------------------—2. 不考虑通道间的融合（只有一个通道中含有非0数）----------------------------</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># zeros:不考虑通道之间影响	channel:不考虑相邻点影响  	weight[2,2,3,3]：共四个3*3矩阵</span></span><br><span class="line">zeros = torch.unsqueeze(torch.zeros(kernel_size, kernel_size), <span class="number">0</span>)</span><br><span class="line">channels = torch.unsqueeze(F.pad(torch.ones(<span class="number">1</span>, <span class="number">1</span>), [<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>,<span class="number">1</span>]), <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对应第一个通道卷积核</span></span><br><span class="line">channel_zeros = torch.unsqueeze(torch.cat([channels, zeros], <span class="number">0</span>), <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 对应第二个通道卷积核</span></span><br><span class="line">zeros_ channel= torch.unsqueeze(torch.cat([zeros, channels], <span class="number">0</span>), <span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">identity_conv_weight = torch.cat([channel_zeros, zeros_ channel], <span class="number">0</span>)</span><br><span class="line">identity_conv_bias = torch.zeros([out_channels])</span><br><span class="line"></span><br><span class="line">convx_3 = nn.Conv2d(in_channels, out_channels, kernel_size, padding=<span class="string">"same"</span>)</span><br><span class="line">convx_3.weight = nn.Parameter(identity_conv_weight)</span><br><span class="line">convx_3.bias = nn.Parameter(identity_conv_bias)</span><br><span class="line"></span><br><span class="line">result2 = conv3(x) + conv1_3 + convx_3</span><br><span class="line"><span class="built_in">print</span>(result2)</span><br><span class="line"></span><br><span class="line"><span class="comment">#--------------------------------融合—————————————————————————————————</span></span><br><span class="line">conv_fusion = nn.Conv2d(in_channels, out_channels, kernel_size, padding=<span class="string">"same"</span>)</span><br><span class="line">conv_fusion.weight = nn.Parameter(conv3.weight.data + conv1_3.weight.data + convx_3.weight.data)</span><br><span class="line">conv_fusion.bias = nn.Parameter(conv3.bias.data + conv1_3.bias.data + convx_3.bias.data)</span><br><span class="line">result3 = conv_fusion(x)</span><br><span class="line"><span class="built_in">print</span>(torch.<span class="built_in">all</span>(torch.isclose(result2, result3)))</span><br></pre></td></tr></tbody></table></figure>

<h1 id="Hooks机制"><a href="#Hooks机制" class="headerlink" title="Hooks机制"></a>Hooks机制</h1><blockquote>
<p>Pytorch提供的hooks机制能让用户可以往计算流中的某些部分注入代码，一般来说这些部分无法直接从外部访问。其中主要有两种hooks，一种是添加到张量上的hooks，另一种是添加到Module上的hooks。</p>
</blockquote>
<h2 id="添加到张量上的hooks"><a href="#添加到张量上的hooks" class="headerlink" title="添加到张量上的hooks"></a>添加到张量上的hooks</h2><p>这些添加的<code>hooks</code>能够让用户在反向传播的过程中访问到计算图中的梯度。</p>
<p>下面先来看看反向传播的一个具体例子。</p>
<p><img src="/2022/04/25/pytorch/image-20220523195647470.png" alt="image-20220523195647470"></p>
<ul>
<li><p>当我们将张量<code>a</code>和<code>b</code>相乘的同时也在构建后向图，即创建了一个名字是<code>MulBackward0</code>的节点(其中<code>next_functions</code>表示梯度接下来要传递的到哪些节点即操作的输入)，还有两个<code>AccumulateGrad</code>节点(将反向传播过程中对应张量的梯度作累加)。最后得到的梯度值将保存到叶子张量上(绿框)。</p>
</li>
<li><p><code>张量c</code>属于中间节点，其中<code>grad_fn</code>属性指向后向图中的<code>MulBackward0</code>节点，<code>c.backward()</code>就是对应这个过程将起始梯度传给<code>MulBackward0</code>节点。然后再将该梯度传给<code>MulBackward0</code>节点中的<code>backward</code>函数(本质就是将输入梯度乘对应值得到输入张量的梯度)。本例中前传<code>a*3</code>和<code>2*b</code>所以此节点对应张量<code>a</code>和<code>b</code>的梯度为3，2。</p>
<p>最后要将输出梯度1分别乘3，2得到输入梯度，然后传递给<code>a</code>和<code>b</code>的<code>AccumulateGrad</code>节点来累加梯度，该节点将最终的梯度赋值给对应张量的<code>grad</code>属性。</p>
</li>
</ul>
<p>以上整个过程一旦调用了<code>.backward()</code>反向传播过程中中间节点所产生的梯度(红框)都是无法访问到的，无法打印、修改，用户只能查看反向回传完之后叶子节点上的梯度。</p>
<p><strong>hooks的作用在于能够让用户访问到反向传播过程中的梯度张量，同时可以修改这些梯度值。</strong></p>
<hr>
<p>我们给中间的张量都添加<code>hooks</code>看看计算图会有什么变化</p>
<p><img src="/2022/04/25/pytorch/image-20220523204413424.png" alt="image-20220523204413424"></p>
<ul>
<li><p>第一个添加的<code>hook</code>: <code>c.register_hook</code>中传入了一个函数<code>c_hook</code>,该函数有一个参数表示梯度，并可以返回一个新梯度。当向张量<code>c</code>注册这个<code>hook</code>函数，首先它会被添加到张量<code>c</code>的<code>_backward_hooks</code>（是个有序字典，添加<code>hook</code>函数的顺序很重要，反向传播中会按照之前添加的顺序调用）。</p>
</li>
<li><p>如果用户想让梯度保存在某个中间节点的话，需要调用<code>中间节点的retain_grad函数</code>(默认情况下，只有叶子节点会保存梯度值)。在调用此函数后，会往<code>_backward_hooks</code>字典中注册<code>retain_grad_hook</code>函数，当该函数被调用，传给它的梯度值会保存到中间张量的<code>grad</code>属性上。</p>
</li>
<li><p><strong>需要注意的是反向传播过程中<code>hook</code>系统是如何工作的，往中间节点和叶子节点上添加<code>hook</code>是有区别的。</strong>当往叶子节点添加<code>hook</code>函数，该函数就只是被添加到<code>_backward_hooks</code>字典中。而往中间节点添加<code>hook</code>函数的同时，所有在反向图中关联了该中间向量的节点都会被通知，上图中<code>MulBackward0</code>节点关联了张量<code>c</code>，即将<code>_backward_hooks</code>字典添加到<code>MulBackward0</code>节点的<code>pre_hooks</code>列表中，这些列表中函数都会在梯度被传递给<code>backward</code>函数前被调用。</p>
<p>在注册好所有hook函数后，过一遍反向传播过程。</p>
</li>
</ul>
<p><img src="/2022/04/25/pytorch/image-20220523220453700.png" alt="image-20220523220453700"></p>
<p>流程：<code>1.0</code>-&gt;<code>MulBackward0</code>-&gt;<code>pre_hooks</code>-&gt;<code>_backward_hooks</code>-&gt;将梯度2-&gt;<code>backward</code>-&gt;8,12(12会被传递给叶子张量d的<code>AccumulateGrad</code>节点，<strong>同时该节点会检查其所关联的张量是否有注册</strong><code>backward_hooks</code>，如果注册了（<code>d</code>中注册了，<code>a,b</code>未注册），该节点会把梯度传给这些注册的<code>hook</code>函数处理，然后再保存到张量的<code>grad</code>属性上)-&gt;梯度10-&gt;<code>backward</code>-&gt; ….</p>
<p><img src="/2022/04/25/pytorch/image-20220523221008946.png" alt="image-20220523221008946"></p>
<p><code>h.remove()</code>可以将<code>hook</code>函数从保存它的<code>_backward_hooks</code>字典中移除，如上图在调用<code>e.backward</code>之前调用了<code>h.remove</code>，那么在反向传播中这个<code>c_hook</code>函数就不会被调用，另外要注意的是，在这些<code>hooks</code>函数中不要对梯度张量本身做任何修改，即不要对输入梯度做<code>inplace</code>操作如<code>grad *= 100</code>。原因是这个梯度有可能同时被传递给后向图中其他节点。</p>
<h2 id="Module上的hooks"><a href="#Module上的hooks" class="headerlink" title="Module上的hooks"></a>Module上的hooks</h2><ul>
<li><code>Module</code>上的<code>hooks</code>函数是在<code>forward</code>函数调用之前或之后被调用的。下面例子实现了一个<code>SumNet</code>模块，其<code>forward</code>函数是将三个张量相加并返回结果。</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">SumNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(SumNet，self)._.init__()</span><br><span class="line">        </span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">a，b，c</span>):</span><br><span class="line">        d = a + b + c</span><br><span class="line">        <span class="keyword">return</span> d</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward_pre_hook</span>(<span class="params">module，inputs</span>):</span><br><span class="line">    a，b = inputs</span><br><span class="line">    <span class="keyword">return</span> a + <span class="number">10</span>，b</span><br><span class="line"></span><br><span class="line"><span class="comment">#此处inputs参数是forward_pre_hook函数的返回值input(11,2),output的输出会覆盖forward函数中返回的输出，即116</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">forward_hook</span>(<span class="params">module，inputs， output</span>):</span><br><span class="line">    <span class="keyword">return</span> output + <span class="number">100</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    sum_net = SumNet()</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 往模块注册在forward之前调用的hook函数，执行完该函数后，会将更新后的a=11, b=2, c=3输入forward函数，并返回d=16</span></span><br><span class="line">    sum_net.register_forward_pre_hook(forward_pre_hook)</span><br><span class="line">    <span class="comment">#注册在forward之后调用的hook函数</span></span><br><span class="line">    sum_net.register_forward_hook( forward_hook)</span><br><span class="line">    </span><br><span class="line">    a = torch.tensor(<span class="number">1.0</span>，requires_grad=<span class="literal">True</span>)</span><br><span class="line">    b = torch.tensor(<span class="number">2.0</span>，requires_grad=<span class="literal">True</span>)</span><br><span class="line">    c = torch.tensor(<span class="number">3.0</span>，requires_grad=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#a, b作为位置参数传入，c作为 关键字参数传入</span></span><br><span class="line">    d = sum_net(a，b，c=c)</span><br><span class="line">    <span class="built_in">print</span>( <span class="string">'d: '</span>, d)		<span class="comment">#116</span></span><br></pre></td></tr></tbody></table></figure>

<ul>
<li>和往张量上注册<code>hooks</code>函数一样，同样可以用一个变量来保存注册<code>hooks</code>函数时的返回值，即<code>hook</code>函数的句柄（handle to the hook），这样方便后面移除<code>hook</code>。</li>
</ul>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">main</span>():</span><br><span class="line">    sum_net = SumNet()</span><br><span class="line">    </span><br><span class="line">	forward_pre_hook_handle = sum_net.register_forward_pre_hook (forward_pre_hook)</span><br><span class="line">	forward_hook_handle = sum_net.register_forward_hook(forward_hook)</span><br><span class="line">	</span><br><span class="line">    a = torch.tensor(<span class="number">1.0</span>，requires_grad=<span class="literal">True</span>)</span><br><span class="line">    b = torch.tensor(<span class="number">2.0</span>，requires_grad=<span class="literal">True</span>)</span><br><span class="line">    c = torch.tensor(<span class="number">3.0</span>，requires_grad=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    d = sum_net(a，b，c=c)</span><br><span class="line">    <span class="built_in">print</span>( <span class="string">'d: '</span>, d)		<span class="comment">#116</span></span><br><span class="line">    </span><br><span class="line">	forward_pre_hook_handle.remove()</span><br><span class="line">	forward_hook_handle.remove()</span><br><span class="line">    </span><br><span class="line">    d = sum_net(a，b，c=c)</span><br><span class="line">    <span class="built_in">print</span>( <span class="string">'d: '</span>, d)		<span class="comment">#6</span></span><br></pre></td></tr></tbody></table></figure>

<ul>
<li><p><code>Module</code>还有另一种<code>hook</code>，即<code>backward_hook</code>。<code>register_backward_hook(backward_hook)</code></p>
<figure class="highlight plaintext"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># args：实例、输入梯度、输出梯度</span><br><span class="line">def backward_hook(module，grad_input，grad_output):</span><br><span class="line">	print('module:', module)</span><br><span class="line">	print('grad_input:',grad_input)</span><br><span class="line">	print('grad_output:',grad_output)</span><br></pre></td></tr></tbody></table></figure>

<blockquote>
<p><a target="_blank" rel="noopener" href="https://www.bilibili.com/video/BV1MV411t7td?spm_id_from=333.337.search-card.all.click">PyTorch Hooks Explained - In-depth Tutorial</a></p>
</blockquote>
</li>
</ul>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>CY</span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>Permalink:</span>
                        <span><a href="http://example.com/2022/04/25/pytorch/">http://example.com/2022/04/25/pytorch/</a></span>
                    </p>
                
                
                    <p class="copyright-item">
                        <span>License:</span>
                        <span>Copyright (c) 2019 <a target="_blank" rel="noopener" href="http://creativecommons.org/licenses/by-nc/4.0/">CC-BY-NC-4.0</a> LICENSE</span>
                    </p>
                
                
                     <p class="copyright-item">
                         <span>Slogan:</span>
                         <span>Do you believe in <strong>DESTINY</strong>?</span>
                     </p>
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/torch/"># torch</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2022/05/15/paper/">A White-box Deep Network from the Principle of Maximizing Rate Reduction</a>
            
            
            <a class="next" rel="next" href="/2022/03/30/convnext/">convnext</a>
            
        </section>


    </article>
</div>



    <div id="gitalk-container"></div>
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css">
<script src="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js"></script>
<div id="gitalk-container"></div>
<script type="text/javascript">
      var gitalk = new Gitalk({
        clientID: '9810f94b2996825e7931',
        clientSecret: 'c1aee8c436730130e3ad18694d20888a1ee13bce',
        repo: 'Seperendity.github.io',
        owner: 'Seperendity',
        admin: 'Seperendity',
        id: location.pathname,
        labels: 'Gitalk'.split(',').filter(l => l),
        perPage: 10,
        pagerDirection: 'last',
        createIssueManually: true,
        distractionFreeMode: false
      })
      gitalk.render('gitalk-container')
</script>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span>© CY | 2022 😉 Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a>
		|
		<!-- 访客数量 -->
		
		  <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<span class="site-uv">

  <i class="iconfont icon-yonghu "></i>

 <i class="busuanzi-value" id="busuanzi_value_site_uv"></i>

</span>&nbsp;





<span class="site-pv">

 <i class="iconfont icon-jiaoyinzujifangke "></i>

 <i class="busuanzi-value" id="busuanzi_value_site_pv"></i>

</span>


		
		</span>
    </div>
</footer>

<script>
    $(document).ready(function () {

        var int = setInterval(fixCount, 50);  // 50ms周期检测函数
        var pvcountOffset = 80000;  // 初始化首次数据
        var uvcountOffset = 20000;

        function fixCount() {
            if (document.getElementById("busuanzi_container_site_pv").style.display != "none") {
                $("#busuanzi_value_site_pv").html(parseInt($("#busuanzi_value_site_pv").html()) + pvcountOffset);
                clearInterval(int);
            }
            if ($("#busuanzi_container_site_pv").css("display") != "none") {
                $("#busuanzi_value_site_uv").html(parseInt($("#busuanzi_value_site_uv").html()) + uvcountOffset); // 加上初始数据 
                clearInterval(int); // 停止检测
            }
        }
    });
</script>

    </div>
	
	<!-- 搜索功能 -->
	<!-- Chic/layout.ejs -->
	<div id="u-search">
		<div class="modal">
			<div class="modal-header">
				<div class="container">
					<form id="u-search-modal-form" class="u-search-modal-form">
						<button type="submit" class="form-submit-btn">
							<img src="/image/search.png" class="search-btn-img" />
						</button>
						<input placeholder="搜索内容..." class="form-input" id="modal-form-input">
					</form>
					<a class="modal-close">x</a>
				</div>
				<div class="search-loading">
					<div class="search-loading-bar"></div>
				</div>
			</div>
			<div class="modal-body">
			</div>
		</div>
		<div class="modal-overlay"></div>
	</div>
<script src="/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05"></script><script>L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"log":false,"model":{"jsonPath":"/live2dw/assets/haruto.model.json"},"display":{"position":"right","width":150,"height":300},"mobile":{"show":true},"react":{"opacity":0.7}});</script></body>
<script>
!
function() {
    function n(n, e, t) {
        return n.getAttribute(e) || t
    }
    function e(n) {
        return document.getElementsByTagName(n)
    }
    function t() {
        var t = e("script"),
        o = t.length,
        i = t[o - 1];
        return {
            l: o,
            z: n(i, "zIndex", -1),     //置于主页面背后
            o: n(i, "opacity", .5),     //线条透明度
            c: n(i, "color", "0,0,0"),  //线条颜色
            n: n(i, "count", 100)    //线条数量
        }
    }
    function o() {
        a = m.width = window.innerWidth || document.documentElement.clientWidth || document.body.clientWidth,
        c = m.height = window.innerHeight || document.documentElement.clientHeight || document.body.clientHeight
    }
    function i() {
        r.clearRect(0, 0, a, c);
        var n, e, t, o, m, l;
        s.forEach(function(i, x) {
            for (i.x += i.xa, i.y += i.ya, i.xa *= i.x > a || i.x < 0 ? -1 : 1, i.ya *= i.y > c || i.y < 0 ? -1 : 1, r.fillRect(i.x - .5, i.y - .5, 1, 1), e = x + 1; e < u.length; e++) n = u[e],
            null !== n.x && null !== n.y && (o = i.x - n.x, m = i.y - n.y, l = o * o + m * m, l < n.max && (n === y && l >= n.max / 2 && (i.x -= .03 * o, i.y -= .03 * m), t = (n.max - l) / n.max, r.beginPath(), r.lineWidth = t / 2, r.strokeStyle = "rgba(" + d.c + "," + (t + .2) + ")", r.moveTo(i.x, i.y), r.lineTo(n.x, n.y), r.stroke()))
        }),
        x(i)
    }
    var a, c, u, m = document.createElement("canvas"),
    d = t(),
    l = "c_n" + d.l,
    r = m.getContext("2d"),
    x = window.requestAnimationFrame || window.webkitRequestAnimationFrame || window.mozRequestAnimationFrame || window.oRequestAnimationFrame || window.msRequestAnimationFrame ||
    function(n) {
        window.setTimeout(n, 1e3 / 45)
    },
    w = Math.random,
    y = {
        x: null,
        y: null,
        max: 2e4
    };
    m.id = l,
    m.style.cssText = "position:fixed;top:0;left:0;z-index:" + d.z + ";opacity:" + d.o,
    e("body")[0].appendChild(m),
    o(),
    window.onresize = o,
    window.onmousemove = function(n) {
        n = n || window.event,
        y.x = n.clientX,
        y.y = n.clientY
    },
    window.onmouseout = function() {
        y.x = null,
        y.y = null
    };
    for (var s = [], f = 0; d.n > f; f++) {
        var h = w() * a,
        g = w() * c,
        v = 2 * w() - 1,
        p = 2 * w() - 1;
        s.push({
            x: h,
            y: g,
            xa: v,
            ya: p,
            max: 6e3
        })
    }
    u = s.concat([y]),
    setTimeout(function() {
        i()
    },
    100)
} ();
</script>

<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=350&t=m&d=1NqKKNlM62oDkLYA7mQMmVg49mUH_Ib-6MkRgvd04o8&co=2d78ad&cmo=ffc253&cmn=ff5353&ct=ffffff'></script>

</html>